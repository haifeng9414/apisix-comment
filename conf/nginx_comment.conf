# Configuration File - Nginx Server Configs
# This is a read-only file, do not try to modify it.

master_process on;

worker_processes auto;

error_log logs/error.log warn;
pid logs/nginx.pid;

worker_rlimit_nofile 20480;

events {
    accept_mutex off;
    worker_connections 10620;
}

worker_rlimit_core  16G;

worker_shutdown_timeout 240s;

# 通过APISIX_PROFILE环境变量设置想要激活的profile
env APISIX_PROFILE;

### 当config-default.yaml文件中设置stream_proxy为true时这里还会有一段stream的配置
### end

http {
    lua_package_path  "$prefix/deps/share/lua/5.1/?.lua;$prefix/deps/share/lua/5.1/?/init.lua;/Users/donghaifeng/PyCharmProjects/apisix/?.lua;/Users/donghaifeng/PyCharmProjects/apisix/?/init.lua;;/usr/local/share/lua/5.3/?.lua;/usr/local/share/lua/5.3/?/init.lua;/usr/local/lib/lua/5.3/?.lua;/usr/local/lib/lua/5.3/?/init.lua;./?.lua;./?/init.lua;";
    lua_package_cpath "$prefix/deps/lib64/lua/5.1/?.so;$prefix/deps/lib/lua/5.1/?.so;;/usr/local/lib/lua/5.3/?.so;/usr/local/lib/lua/5.3/loadall.so;./?.so;";

    # 各种共享缓存的大小配置
    lua_shared_dict plugin-limit-req     10m;
    lua_shared_dict plugin-limit-count   10m;
    lua_shared_dict prometheus-metrics   10m;
    lua_shared_dict plugin-limit-conn    10m;
    lua_shared_dict upstream-healthcheck 10m;
    lua_shared_dict worker-events        10m;
    lua_shared_dict lrucache-lock        10m;
    lua_shared_dict skywalking-tracing-buffer    100m;
    lua_shared_dict balancer_ewma        10m;
    lua_shared_dict balancer_ewma_locks  10m;
    lua_shared_dict balancer_ewma_last_touched_at 10m;

    # for openid-connect plugin
    lua_shared_dict discovery             1m; # cache for discovery metadata documents
    lua_shared_dict jwks                  1m; # cache for JWKs
    lua_shared_dict introspection        10m; # cache for JWT verification results

    # for custom shared dict

    ### 当config-default.yaml文件中配置了proxy-cache插件时，将会添加下面的配置
    # for proxy cache
    # proxy_cache_path指令用于开启缓存功能，将后端服务的响应保存在本地磁盘上，客户端请求只要满足缓存的条件就会命中缓存，Nginx就不会再将
    # 请求转发到后端的服务上
    # 第一个参数用于设置保存缓存的路径，参数keys_zone也是必须的，用来设置共享内存缓存区的名称和大小，共享缓冲区用来保存缓存条目的原信息，
    # 缓冲区的名称将会被proxy_cache指令使用
    # 为了避免缓存路径下缓存的文件过多导致文件系统处理缓慢，可以通过levels参数设置路径层级，levels=1:2表示是两级目录，1和2表示用1位和2
    # 位16进制来命名目录名称，所以levels=1:2时一级目录有16个，二级目录有16*16=256个
    # inactive参数用于配置缓存多久没被访问后删除
    # max_size参数用于通过LRU算法控制缓存总大小
    proxy_cache_path /tmp/disk_cache_one levels=1:2 keys_zone=disk_cache_one:50m inactive=1d max_size=1G;
    ### end

    ### 当config-default.yaml文件中配置了proxy-cache插件时，将会添加下面的配置
    # for proxy cache
    # 如果$upstream_cache_zone变量的值，如果该变量值为disk_cache_one，则设置$upstream_cache_zone_info变量的值为/tmp/disk_cache_one,1:2
    map $upstream_cache_zone $upstream_cache_zone_info {
        disk_cache_one /tmp/disk_cache_one,1:2;
    }
    ### end

    # 设置验证服务端证书的深度
    lua_ssl_verify_depth 5;
    ssl_session_timeout 86400;

    # 默认的情况下nginx引用header变量时不能使用带下划线的变量，当underscores_in_headers为on时header的变量可以带有下划线
    underscores_in_headers on;

    # 默认为true，表示当TCP或者UDP的cosockets发生错误时是否记录error，如果代码中错误处理已经很完善了，也记录了日志，就可以关闭该选项
    lua_socket_log_errors off;

    # 设置解析上游服务域名时使用的dns地址
    resolver 198.18.0.2 valid=30;
    # 解析上游服务域名的超时时间
    resolver_timeout 5;

    # 配置是否自动缓存http 1.0的响应，主要用于支持http 1.0的keep-alive
    lua_http10_buffering off;

    # PCRE正则库相关配置
    lua_regex_match_limit 100000;
    lua_regex_cache_max_entries 8192;

    log_format main '$remote_addr - $remote_user [$time_local] $http_host "$request" $status $body_bytes_sent $request_time "$http_referer" "$http_user_agent" $upstream_addr $upstream_status $upstream_response_time';

    access_log logs/access.log main buffer=16384 flush=3;
    # 缓存打开的文件的信息，包括打开的文件描述符，文件的大小和修改时间、目录存在的信息、文件查找错误，例如“找不到文件”，“没有读取权限”等
    open_file_cache  max=1000 inactive=60;
    # 设置客户端请求包体的最大大小，默认1m，如果超过该配置，则会返回413(Request Entity Too Large)，设置为0表示不限制
    client_max_body_size 0;
    keepalive_timeout 60s;
    # 如果客户端在指定的时间内没有发送header，则返回408(Request Time-out)
    client_header_timeout 60s;
    # 如果客户端在指定的时间内没有发送body，则返回408(Request Time-out)
    client_body_timeout 60s;
    # 如果客户端在指定的时间内没有读取发送过去的响应，连接将被关闭
    send_timeout 10s;

    # 是否在响应中加上Server header，该header用于告诉客户端nginx的版本
    server_tokens off;

    include mime.types;
    # 在Content-Type header中添加charset=utf-8
    charset utf-8;

    real_ip_header X-Real-IP;

    set_real_ip_from 127.0.0.1;
    set_real_ip_from unix:;

    upstream apisix_backend {
        # 这个server的配置没有意义，只是nginx的语法要求
        server 0.0.0.1;
        # 通过http_balancer_phase方法实现负载均衡
        balancer_by_lua_block {
            apisix.http_balancer_phase()
        }

        # 空闲的上游服务keepalive连接的最大数量
        keepalive 320;
    }

    # master进程初始化时执行
    init_by_lua_block {
        # 加载/usr/local/Cellar/openresty/1.17.8.2_1/lualib/resty/core.lua，该文件会加载其他OpenResty的核心lua文件
        require "resty.core"
        # 加载apisix/init.lua（lua_package_path配置中有一条/Users/donghaifeng/PyCharmProjects/apisix/?/init.lua）
        apisix = require("apisix")

        local dns_resolver = { "198.18.0.2", }
        local args = {
            dns_resolver = dns_resolver,
        }
        apisix.http_init(args)
    }

    # worker进程初始化时执行
    init_worker_by_lua_block {
        apisix.http_init_worker()
    }

    server {
        # 在3.9内核以前，为了支持多进程模型像HAProxy，nginx等，大家不约而同的采用的fork的做法，即在父进程里，监听一个ip+port，然后
        # fork出N个子进程，子进程天然继承了父进程的listen socket的句柄，这样就可以实现多个进程在一个ip+port上执行accept操作了
        # 但因为是fork出来的，所以在kernel里，仍然是一个句柄，多个进程执行accept还是有竞争关系，所以nginx需要配置accept_mutex这样的
        # 开关来解决"惊群"问题。
        # 当开启reuseport后，每个监听地址将会有多个句柄，具体来说是一个worker一个，这样每个worker的listen socket就独立开了，避免了多
        # 进程的竞争。
        listen 9080 reuseport;
        listen 9443 ssl http2 reuseport;

        # listen ipv6
        listen [::]:9080 reuseport;
        listen [::]:9443 ssl http2 reuseport;

        ssl_certificate      cert/apisix.crt;
        ssl_certificate_key  cert/apisix.key;
        ssl_session_cache    shared:SSL:20m;
        ssl_session_timeout 10m;

        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers on;

        location = /apisix/nginx_status {
            allow 127.0.0.0/24;
            deny all;
            access_log off;
            # stub_status模块主要用于返回Nginx的一些状态信息
            stub_status;
        }

        # 处理dashboard项目发送的请求
        location /apisix/admin {
                allow 127.0.0.0/24;
                deny all;

            content_by_lua_block {
                apisix.http_admin()
            }
        }

        location /apisix/dashboard {
                allow 127.0.0.0/24;
                deny all;

            alias dashboard/;

            try_files $uri $uri/index.html /index.html =404;
        }

        ssl_certificate_by_lua_block {
            apisix.http_ssl_phase()
        }

        location / {
            # 初始化若干变量
            # Nginx变量的创建只能发生在Nginx配置加载的时候，或者说Nginx启动的时候；而赋值操作则只会发生在请求实际处理的时候。这意味着
            # 不创建而直接使用变量会导致启动失败，同时也意味着无法在请求处理时动态地创建新的Nginx变量。
            # 另外Nginx的变量可见范围是整个配置，即无论在哪个location声明了变量，该变量在整个Nginx都是可见的，但每个请求都有所有变量的
            # 独立副本，或者说都有各变量用来存放值的容器的独立副本，彼此互不干扰。
            set $upstream_mirror_host        '';
            set $upstream_scheme             'http';
            set $upstream_host               $host;
            set $upstream_upgrade            '';
            set $upstream_connection         '';
            set $upstream_uri                '';

            access_by_lua_block {
                apisix.http_access_phase()
            }

            proxy_http_version 1.1;
            proxy_set_header   Host              $upstream_host;
            proxy_set_header   Upgrade           $upstream_upgrade;
            proxy_set_header   Connection        $upstream_connection;
            proxy_set_header   X-Real-IP         $remote_addr;
            proxy_pass_header  Server;
            proxy_pass_header  Date;

            ### the following x-forwarded-* headers is to send to upstream server

            set $var_x_forwarded_for        $remote_addr;
            set $var_x_forwarded_proto      $scheme;
            set $var_x_forwarded_host       $host;
            set $var_x_forwarded_port       $server_port;

            if ($http_x_forwarded_for != "") {
                set $var_x_forwarded_for "${http_x_forwarded_for}, ${realip_remote_addr}";
            }
            if ($http_x_forwarded_proto != "") {
                set $var_x_forwarded_proto $http_x_forwarded_proto;
            }
            if ($http_x_forwarded_host != "") {
                set $var_x_forwarded_host $http_x_forwarded_host;
            }
            if ($http_x_forwarded_port != "") {
                set $var_x_forwarded_port $http_x_forwarded_port;
            }

            proxy_set_header   X-Forwarded-For      $var_x_forwarded_for;
            proxy_set_header   X-Forwarded-Proto    $var_x_forwarded_proto;
            proxy_set_header   X-Forwarded-Host     $var_x_forwarded_host;
            proxy_set_header   X-Forwarded-Port     $var_x_forwarded_port;

            ###  the following configuration is to cache response content from upstream server

            ### 当config-default.yaml文件中配置了proxy-cache插件时，将会添加下面的配置
            set $upstream_cache_zone            off;
            set $upstream_cache_key             '';
            set $upstream_cache_bypass          '';
            set $upstream_no_cache              '';
            set $upstream_hdr_expires           '';
            set $upstream_hdr_cache_control     '';

            proxy_cache                         $upstream_cache_zone;
            proxy_cache_valid                   any 10s;
            proxy_cache_min_uses                1;
            proxy_cache_methods                 GET HEAD;
            proxy_cache_lock_timeout            5s;
            proxy_cache_use_stale               off;
            proxy_cache_key                     $upstream_cache_key;
            proxy_no_cache                      $upstream_no_cache;
            proxy_cache_bypass                  $upstream_cache_bypass;

            proxy_hide_header                   Cache-Control;
            proxy_hide_header                   Expires;
            add_header      Cache-Control       $upstream_hdr_cache_control;
            add_header      Expires             $upstream_hdr_expires;
            add_header      Apisix-Cache-Status $upstream_cache_status always;
            ### end

            # 转发请求到上游服务
            proxy_pass      $upstream_scheme://apisix_backend$upstream_uri;

            ### 当config-default.yaml文件中配置了proxy-mirror插件时，将会添加下面的配置
            # 通过mirror能够复制真实流量，在不影响真实业务前提下，通过复制流量可以做故障分析、性能定位、迁移评估等功能
            # 下面的配置会将流量复制到location /proxy_mirror处理
            mirror          /proxy_mirror;
            ### end

            header_filter_by_lua_block {
                apisix.http_header_filter_phase()
            }

            body_filter_by_lua_block {
                apisix.http_body_filter_phase()
            }

            log_by_lua_block {
                apisix.http_log_phase()
            }
        }

        location @grpc_pass {

            access_by_lua_block {
                apisix.grpc_access_phase()
            }

            grpc_set_header   Content-Type application/grpc;
            grpc_socket_keepalive on;
            grpc_pass         grpc://apisix_backend;

            header_filter_by_lua_block {
                apisix.http_header_filter_phase()
            }

            body_filter_by_lua_block {
                apisix.http_body_filter_phase()
            }

            log_by_lua_block {
                apisix.http_log_phase()
            }
        }

        location = /proxy_mirror {
            # 表示当前location只能被内部请求
            internal;

            if ($upstream_mirror_host = "") {
                return 200;
            }

            proxy_pass $upstream_mirror_host$request_uri;
        }
    }
}
